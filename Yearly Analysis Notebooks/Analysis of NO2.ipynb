{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b118749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b_NO2=pd.read_excel(\"/Users/roshanchandraayyadevara/Documents/Dataset_Dessertation/year/NO2_Data.xlsx\",sheet_name='Birmingham')\n",
    "data_l_NO2=pd.read_excel(\"/Users/roshanchandraayyadevara/Documents/Dataset_Dessertation/year/NO2_Data.xlsx\",sheet_name='London')\n",
    "data_lp_NO2=pd.read_excel(\"/Users/roshanchandraayyadevara/Documents/Dataset_Dessertation/year/NO2_Data.xlsx\",sheet_name='Liverpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_NO2=data_b_NO2[[\"Year\",\"Site_Name\",\"City\",\"Annual_Mean\"]]\n",
    "df_l_NO2=data_l_NO2[[\"Year\",\"Site_Name\",\"City\",\"Annual_Mean\"]]\n",
    "df_lp_NO2=data_lp_NO2[[\"Year\",\"Site_Name\",\"City\",\"Annual_Mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_NO2=data_b_NO2.groupby('Year').agg(NO2_Birmingham=('Annual_Mean', 'mean')).reset_index()\n",
    "df_l_NO2=data_l_NO2.groupby('Year').agg(NO2_London=('Annual_Mean', 'mean')).reset_index()\n",
    "df_lp_NO2=data_lp_NO2.groupby('Year').agg(NO2_Liverpool=('Annual_Mean', 'mean')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1beebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_NO2=df_b_NO2['NO2_Birmingham']\n",
    "l_NO2=df_l_NO2['NO2_London']\n",
    "lp_NO2=df_lp_NO2['NO2_Liverpool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465003ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum of Birmingham\",max(B_NO2))\n",
    "print(\"Maximum of London\",max(l_NO2))\n",
    "print(\"Maximum of Liverpool\",max(lp_NO2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d35a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum of Birmingham\",min(B_NO2))\n",
    "print(\"Minimum of London\",min(l_NO2))\n",
    "print(\"Minimum of Liverpool\",min(lp_NO2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad896b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SD of Birmingham\",B_NO2.std())\n",
    "print(\"SD of London\",l_NO2.std())\n",
    "print(\"SD of Liverpool\",lp_NO2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840889e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance of Birmingham\",B_NO2.var())\n",
    "print(\"Variance of London\",l_NO2.var())\n",
    "print(\"Variance of Liverpool\",lp_NO2.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ced363",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of Birmingham\",B_NO2.mean())\n",
    "print(\"Mean of London\",l_NO2.mean())\n",
    "print(\"Mean of Liverpool\",lp_NO2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b7db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Assuming B_NO2, l_NO2, and lp_NO2 are pandas Series containing the data for Birmingham, London, and Liverpool respectively.\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Birmingham': B_NO2,\n",
    "    'London': l_NO2,\n",
    "    'Liverpool': lp_NO2\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(data['Birmingham'], data['London'], data['Liverpool'])\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for statistical significance (alpha = 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"The means are significantly different among the cities.\")\n",
    "    # Perform Tukey's HSD test for post hoc analysis\n",
    "    mc_result = mc.MultiComparison(data.melt(var_name='City', value_name='NO2 Concentration')['NO2 Concentration'],\n",
    "                                   data.melt(var_name='City', value_name='NO2 Concentration')['City'])\n",
    "    tukey_result = mc_result.tukeyhsd()\n",
    "    print(tukey_result)\n",
    "else:\n",
    "    print(\"There is no significant difference among the cities.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data frames\n",
    "merged_df = df_b_NO2.merge(df_l_NO2, on='Year').merge(df_lp_NO2, on='Year')\n",
    "\n",
    "# Create a new data frame for Seaborn (melt the data to make it long-form)\n",
    "melted_df = pd.melt(merged_df, id_vars='Year', var_name='City', value_name='NO2_Concentration')\n",
    "\n",
    "# Plot box plots using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='City', y='NO2_Concentration', data=melted_df)\n",
    "plt.title('Annual Mean NO2 pollutant of London, Birmingham and Liverpool')\n",
    "plt.ylabel('Annual Mean of NO2')\n",
    "plt.xlabel('City')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness_value = df_lp_NO2['NO2_Liverpool'].skew()\n",
    "\n",
    "kurtosis_value = df_b_NO2['NO2_Birmingham'].kurtosis()\n",
    "print(\"Skewness:\", skewness_value)\n",
    "print(\"Kurtosis:\", kurtosis_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_lp_NO2['NO2_Liverpool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lag = 10  # Example: Compute autocorrelation for lags up to 10.\n",
    "autocorrelation_values = [df_b_NO2['NO2_Birmingham'].autocorr(lag=lag) for lag in range(1, max_lag+1)]\n",
    "\n",
    "print(\"Autocorrelation:\", autocorrelation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67423c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.stem(range(1, max_lag+1), autocorrelation_values, use_line_collection=True)\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.title(\"Autocorrelation Function (ACF)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Assuming B_NO2, l_NO2, and lp_NO2 are pandas Series containing the data for Birmingham, London, and Liverpool, respectively.\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Birmingham': B_NO2,\n",
    "    'London': l_NO2,\n",
    "    'Liverpool': lp_NO2\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(data['Birmingham'], data['London'], data['Liverpool'])\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for statistical significance (alpha = 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"The means are significantly different among the cities.\")\n",
    "    \n",
    "    # Perform Fisher's LSD test for post hoc analysis\n",
    "    k = len(data.columns)  # Number of groups (cities)\n",
    "    n_total = data.shape[0]  # Total number of observations\n",
    "    group_means = data.mean()  # Mean values for each city\n",
    "    group_n = data.count()  # Sample sizes for each city\n",
    "\n",
    "    # Calculate the LSD value\n",
    "    lsd_value = np.sqrt(f.ppf(1 - 0.05, k - 1, n_total - k) * np.var(data.values, ddof=1) / n_total)\n",
    "\n",
    "    # Perform all pairwise comparisons\n",
    "    for i, city1 in enumerate(data.columns):\n",
    "        for j, city2 in enumerate(data.columns[i+1:], i+1):\n",
    "            mean_difference = group_means[city1] - group_means[city2]\n",
    "            critical_value = lsd_value * np.sqrt(1/group_n[city1] + 1/group_n[city2])\n",
    "\n",
    "            if abs(mean_difference) > critical_value:\n",
    "                print(f\"{city1} and {city2} have significantly different pollution levels.\")\n",
    "else:\n",
    "    print(\"There is no significant difference among the cities.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ad6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Assuming B_NO2, l_NO2, and lp_NO2 are pandas Series containing the data for Birmingham, London, and Liverpool respectively.\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Birmingham': B_NO2,\n",
    "    'London': l_NO2,\n",
    "    'Liverpool': lp_NO2\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(data['Birmingham'], data['London'], data['Liverpool'])\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for statistical significance (alpha = 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"The means are significantly different among the cities.\")\n",
    "    # Perform Tukey's HSD test for post hoc analysis\n",
    "    mc_result = mc.MultiComparison(data.melt(var_name='City', value_name='NO Concentration')['NO Concentration'],\n",
    "                                   data.melt(var_name='City', value_name='NO Concentration')['City'])\n",
    "    tukey_result = mc_result.tukeyhsd()\n",
    "    print(tukey_result)\n",
    "\n",
    "    # Get the increasing order of cities based on their NO2 concentrations\n",
    "    mean_values = data.mean().sort_values(ascending=False)  # Sort in ascending order\n",
    "    increasing_order = mean_values.index.tolist()\n",
    "    print(\"Increasing order of cities based on NO2 concentrations:\")\n",
    "    print(increasing_order)\n",
    "\n",
    "else:\n",
    "    print(\"There is no significant difference among the cities.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6988cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
